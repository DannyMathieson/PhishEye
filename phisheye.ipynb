{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PhishEye"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install dnstwist\n",
    "# pip install DNSPython\n",
    "# pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dnstwist\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzz = dnstwist.Fuzzer(\"www.google.com\")\n",
    "fuzz.generate()\n",
    "len(fuzz.permutations())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dnstwist.run(domain='google.com', registered=True, format='null')\n",
    "reg = [d['domain'] for d in data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_non = dnstwist.run(domain='google.com', unregistered=True, format='null')\n",
    "nonreg = [d['domain'] for d in data_non]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2):\n",
    "    return list(set(lst1) & set(lst2))\n",
    "\n",
    "intersection(reg, nonreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f'The number of registered permutations is: {len(reg)}')\n",
    "print (f'The number of non registered permutations is: {len(nonreg)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (reg[::15])\n",
    "print (nonreg[::150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains_df = pd.read_csv('./top-1m.csv', header=None, index_col=0)\n",
    "domains_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dicts(domain_list):\n",
    "    reg_dict, nonreg_dict = {}, {}\n",
    "    for domain in domain_list:\n",
    "        data_reg = dnstwist.run(domain=f'{domain}', registered=True, format='null')\n",
    "        reg = [d['domain'] for d in data_reg]\n",
    "        reg_dict[domain]  = len(reg)\n",
    "        data_nonreg = dnstwist.run(domain=f'{domain}', unregistered=True, format='null')\n",
    "        nonreg = [d['domain'] for d in data_nonreg]\n",
    "        nonreg_dict[domain]  = len(nonreg)\n",
    "    return reg_dict, nonreg_dict\n",
    "# eda_reg, eda_nonreg = get_dicts(list(domains_df[1].values[:10]))\n",
    "# eda_reg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = list(eda_reg.keys())\n",
    "# Yreg = list(eda_reg.values())\n",
    "# Znonreg= list(eda_nonreg.values())\n",
    "# X_axis = np.arange(len(x))\n",
    "  \n",
    "# plt.bar(x, Znonreg, color='steelblue')\n",
    "# plt.bar(x, Yreg, bottom=Znonreg, color='darkorange')\n",
    "  \n",
    "# plt.xlabel(\"Domains\")\n",
    "# plt.ylabel(\"Number of Permutations\")\n",
    "# plt.title(\"Number of Registered and Non Registered Domain Permutations\")\n",
    "# plt.xticks(rotation=30)\n",
    "\n",
    "# plt.legend(labels = ['Non Registered: Benign', 'Registered: Malicious'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_twist_dict(domains):\n",
    "    twist_dict = {}\n",
    "    for domain in domains:\n",
    "        #twist_dict[domain] = [[],[]]\n",
    "        data_reg = dnstwist.run(domain=f'{domain}', registered=True, format='null')\n",
    "        reg = [d['domain'] for d in data_reg]\n",
    "        for homograph in reg:\n",
    "            twist_dict[homograph] = [domain, True]\n",
    "\n",
    "        data_nonreg = dnstwist.run(domain=f'{domain}', unregistered=True, format='null')\n",
    "        nonreg = [d['domain'] for d in data_nonreg]\n",
    "        for homograph in nonreg:\n",
    "            twist_dict[homograph] = [domain, False]\n",
    "    return twist_dict\n",
    "\n",
    "twisted_dict = create_twist_dict(list(domains_df[1].values[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twisted_df = pd.DataFrame.from_dict(twisted_dict, orient='index').reset_index()\n",
    "twisted_df.columns = ['Homograph', 'Domain', 'Registered']\n",
    "twisted_df.to_csv('twisted.csv')\n",
    "twisted_df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strsimpy.levenshtein import Levenshtein\n",
    "from strsimpy.jaro_winkler import JaroWinkler\n",
    "from strsimpy.sorensen_dice import SorensenDice\n",
    "from strsimpy.cosine import Cosine\n",
    "\n",
    "test_string1 = reg[0] # google.com\n",
    "test_string2 = nonreg[1] # g00qle.com\n",
    "\n",
    "levenshtein = Levenshtein()\n",
    "print(levenshtein.distance(test_string1, test_string2))\n",
    "\n",
    "jarowinkler = JaroWinkler()\n",
    "print(jarowinkler.distance(test_string1, test_string2))\n",
    "\n",
    "sorensondice = SorensenDice()\n",
    "print(sorensondice.distance(test_string1, test_string2))\n",
    "\n",
    "cosine = Cosine(2)\n",
    "a = cosine.get_profile(test_string1)\n",
    "b = cosine.get_profile(test_string2)\n",
    "print(cosine.similarity_profiles(a,b))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in twisted_df.iterrows():\n",
    "    twisted_df.loc[index,'Levenshtein'] = levenshtein.distance(row['Domain'], row['Homograph'])\n",
    "    twisted_df.loc[index,'Jaro-Winkler'] = jarowinkler.distance(row['Domain'], row['Homograph'])\n",
    "    twisted_df.loc[index,'Sorenson-Dice'] = sorensondice.distance(row['Domain'], row['Homograph'])\n",
    "    str_to_vect_a= cosine.get_profile(row['Domain'])\n",
    "    str_to_vect_b= cosine.get_profile(row['Homograph'])\n",
    "    twisted_df.loc[index,'Cosine'] = cosine.similarity_profiles(str_to_vect_a, str_to_vect_b)\n",
    "\n",
    "twisted_df    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twisted_df.to_csv('twisted_text_distance.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test sizing\n",
    "lengths = [len(s) for s in twisted_df.Homograph]\n",
    "longest_idx= lengths.index(max(lengths))\n",
    "text = twisted_df.Homograph[longest_idx]\n",
    "img = Image.new('RGB', (1024, 128))\n",
    "# use bold font\n",
    "font = ImageFont.truetype(f\"./fonts/arial bold.ttf\",70)\n",
    "# draw image\n",
    "d1 = ImageDraw.Draw(img)\n",
    "# Center text in image\n",
    "xpos = (img.size[0] / 2) - (font.getsize(text)[0]/2)\n",
    "ypos = (img.size[1] / 2) - (font.getsize(text)[1]/2)\n",
    "d1.text((xpos, ypos), text, fill =(255, 255, 255), font=font)\n",
    "# show image\n",
    "img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "def create_image(string, font='arial.ttf', show=False):\n",
    "    if not os.path.isfile(f'./images/{string}.jpeg'):\n",
    "        img = Image.new('RGB', (1024, 128))\n",
    "        text = string\n",
    "        # use declared font\n",
    "        font = ImageFont.truetype(f\"./fonts/{font}\",70)\n",
    "        # draw image\n",
    "        d1 = ImageDraw.Draw(img)\n",
    "        # Center text in image\n",
    "        xpos = (img.size[0] / 2) - (font.getsize(text)[0]/2)\n",
    "        ypos = (img.size[1] / 2) - (font.getsize(text)[1]/2)\n",
    "        d1.text((xpos, ypos), text, fill =(255, 255, 255), font=font)\n",
    "        # show and save the image\n",
    "        if show:\n",
    "            img.show()\n",
    "        img.save(f'images/{string}.jpeg')\n",
    "\n",
    "for test_string in [test_string1, test_string2]:\n",
    "    create_image(test_string, show=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim, mean_squared_error as mse\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def calculate_similarity(string_a, string_b):\n",
    "    imageA = cv2.imread(f'./images/{string_a}.jpeg')\n",
    "    imageB= cv2.imread(f'./images/{string_b}.jpeg')\n",
    "    gsA = cv2.cvtColor(imageA, cv2.COLOR_BGR2GRAY)\n",
    "    gsB = cv2.cvtColor(imageB, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate the MSE and SSIM\n",
    "    m = mse(gsA, gsB)\n",
    "    s = ssim(gsA, gsB)\n",
    "\n",
    "    return m, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_similarity(test_string1, test_string2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in twisted_df.iterrows():\n",
    "    create_image(row['Domain'])\n",
    "    create_image(row['Homograph'])\n",
    "    m, s = calculate_similarity(row['Domain'], row['Homograph'])\n",
    "    twisted_df.loc[index,'MSE'] = m\n",
    "    twisted_df.loc[index,'SSM'] = s\n",
    "twisted_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twisted_df.to_csv('twisted_viz_sim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(set(twisted_df.MSE.values))[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(twisted_df.MSE, twisted_df.Registered, test_size=0.2, random_state=42)\n",
    "levenshtein_thresholds = np.arange(0, 21, 0.5) # dataset range is 0-20\n",
    "mse_thresholds = np.arange(0, 8640, 10) # dataset range is 0-8640\n",
    "# other_thresholds = np.arange(0, 1, .0001)\n",
    "\n",
    "best_threshold = None\n",
    "best_performance = 0.0\n",
    "\n",
    "# loop over each threshold value and evaluate its performance\n",
    "for threshold in mse_thresholds:\n",
    "    # apply thresholding to the data\n",
    "    labels = np.where(X_train > threshold, True, False)\n",
    "    \n",
    "    # calculate the accuracy score\n",
    "    accuracy = f1_score(y_train, labels, average='weighted',labels=[True])\n",
    "    print(f'{threshold} : {accuracy}')\n",
    "    \n",
    "    # check if this threshold has better performance than the current best threshold\n",
    "    if accuracy > best_performance:\n",
    "        best_threshold = threshold\n",
    "        best_performance = accuracy\n",
    "        \n",
    "# print the best threshold and its associated performance\n",
    "print(\"Best threshold:\", best_threshold)\n",
    "print(\"Best performance:\", best_performance)\n",
    "print (list(zip(y_train, labels)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
